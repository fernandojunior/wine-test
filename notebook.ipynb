{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0  White            7.0              0.27         0.36            20.7   \n",
       "1  White            6.3              0.30         0.34             1.6   \n",
       "2  White            8.1              0.28         0.40             6.9   \n",
       "3  White            7.2              0.23         0.32             8.5   \n",
       "4  White            7.2              0.23         0.32             8.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "\n",
       "   sulphates alcohol  quality  \n",
       "0       0.45     8.8        6  \n",
       "1       0.49     9.5        6  \n",
       "2       0.44    10.1        6  \n",
       "3       0.40     9.9        6  \n",
       "4       0.40     9.9        6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wines: 6497\n",
      "Number of features: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read student data\n",
    "data = pd.read_csv(\"data.csv\", delimiter=\";\")\n",
    "print(\"Data read successfully!\")\n",
    "\n",
    "# Calculate number of wines in dataset\n",
    "n_wines = data.shape[0]\n",
    "\n",
    "# Calculate number of features\n",
    "n_features = data.shape[1] - 1\n",
    "\n",
    "# Print the results\n",
    "display(data.head())\n",
    "\n",
    "print(\"Total number of wines: {}\".format(n_wines))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attribute types**:\n",
    "\n",
    "We have the following column types in the dataset:\n",
    "  - `type`: Categorical (nominal)\n",
    "  - `fixed acidity`: Numeric (continuous)\n",
    "  - `volatile acidity`: Numeric (continuous)\n",
    "  - `citric acid`: Numeric (continuous)\n",
    "  - `residual sugar`: Numeric (continuous)\n",
    "  - `chlorides`: Numeric (continuous)\n",
    "  - `free sulfur dioxide`: Numeric (continuous)\n",
    "  - `total sulfur dioxide`: Numeric (continuous)\n",
    "  - `density`: Numeric (continuous)\n",
    "  - `pH`: Numeric (continuous)\n",
    "  - `sulphates`: Numeric (continuous)\n",
    "  - `alcohol`: Numeric (continuous)\n",
    "  - `quality`: Numeric (ordinal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data balancing\n",
    "\n",
    "A very frequent problem in machine learning models is imbalanced dataset, because an imbalanced dataset may lead to inflated performance estimates ([reference](https://stats.stackexchange.com/questions/28029/training-a-decision-tree-against-unbalanced-data)). Therefore, We will analyse if the dataset response variable is balalanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for the counts of observations in each quality using bars.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fb3f80b70b8>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(\"Plot for the counts of observations in each quality using bars.\")\n",
    "sns.catplot(\"quality\", data=data, hue='quality', kind=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the response variable `quality` is unbalanced and probably we'll have to handle it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler, scale\n",
    "# scaler = MinMaxScaler()\n",
    "# feat = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "# X_all[feat] = scale(X_all[feat])\n",
    "# display(X_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "## Identify feature and target columns\n",
    "\n",
    "It is often the case that the data contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "The code cell below will separate the wine data into feature and target columns to see if any features are non-numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['type', 'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
      "\n",
      "Target column: quality\n",
      "\n",
      "Feature values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0  White            7.0              0.27         0.36            20.7   \n",
       "1  White            6.3              0.30         0.34             1.6   \n",
       "2  White            8.1              0.28         0.40             6.9   \n",
       "3  White            7.2              0.23         0.32             8.5   \n",
       "4  White            7.2              0.23         0.32             8.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "\n",
       "   sulphates alcohol  \n",
       "0       0.45     8.8  \n",
       "1       0.49     9.5  \n",
       "2       0.44    10.1  \n",
       "3       0.40     9.9  \n",
       "4       0.40     9.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature types\n",
      "type                     object\n",
      "fixed acidity           float64\n",
      "volatile acidity        float64\n",
      "citric acid             float64\n",
      "residual sugar          float64\n",
      "chlorides               float64\n",
      "free sulfur dioxide     float64\n",
      "total sulfur dioxide    float64\n",
      "density                 float64\n",
      "pH                      float64\n",
      "sulphates               float64\n",
      "alcohol                  object\n",
      "dtype: object\n",
      "\n",
      "Classes from type feature:\n",
      "['White' 'Red']\n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(data.columns[:-1])\n",
    "\n",
    "# Extract target column 'quality'\n",
    "target_col = data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = data[feature_cols]\n",
    "y_all = data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print(\"\\nFeature values:\")\n",
    "display(X_all.head())\n",
    "\n",
    "print(\"\\nFeature types\")\n",
    "print(X_all.dtypes)\n",
    "\n",
    "print(\"\\nClasses from type feature:\")\n",
    "print(data['type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Feature Columns\n",
    "\n",
    "As we can see, there two non-numeric features that need to be converted: `type` and `alcohol`.\n",
    "\n",
    "The `type` feature only has two classes (`['White' 'Red']`), so it can be reasonably converted into 1/0 (binary) values.\n",
    "\n",
    "The `alcohol` feature is actually a numeric feature, but some rows are wrong non-numeric values, for example `'110.666.666.666.667'`, `'956.666.666.666.667'`, `'923.333.333.333.333'` and so on. Therefore, we will parse the values of this feature into numeric values and replace the wrong values with the mean of all of the values for the feature ([reference](https://machinelearningmastery.com/handle-missing-data-python/)).\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.166089</td>\n",
       "      <td>-0.423183</td>\n",
       "      <td>0.284686</td>\n",
       "      <td>3.206929</td>\n",
       "      <td>-0.314975</td>\n",
       "      <td>0.815565</td>\n",
       "      <td>0.959976</td>\n",
       "      <td>-0.092971</td>\n",
       "      <td>-1.359049</td>\n",
       "      <td>-0.546178</td>\n",
       "      <td>-1.420364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.706073</td>\n",
       "      <td>-0.240949</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>-0.807837</td>\n",
       "      <td>-0.200790</td>\n",
       "      <td>-0.931107</td>\n",
       "      <td>0.287618</td>\n",
       "      <td>-0.093888</td>\n",
       "      <td>0.506915</td>\n",
       "      <td>-0.277351</td>\n",
       "      <td>-0.831728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.682458</td>\n",
       "      <td>-0.362438</td>\n",
       "      <td>0.559966</td>\n",
       "      <td>0.306208</td>\n",
       "      <td>-0.172244</td>\n",
       "      <td>-0.029599</td>\n",
       "      <td>-0.331660</td>\n",
       "      <td>-0.093744</td>\n",
       "      <td>0.258120</td>\n",
       "      <td>-0.613385</td>\n",
       "      <td>-0.327183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.666161</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.642523</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>0.928254</td>\n",
       "      <td>1.243074</td>\n",
       "      <td>-0.093678</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.882212</td>\n",
       "      <td>-0.495365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.666161</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.642523</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>0.928254</td>\n",
       "      <td>1.243074</td>\n",
       "      <td>-0.093678</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.882212</td>\n",
       "      <td>-0.495365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0     1      -0.166089         -0.423183     0.284686        3.206929   \n",
       "1     1      -0.706073         -0.240949     0.147046       -0.807837   \n",
       "2     1       0.682458         -0.362438     0.559966        0.306208   \n",
       "3     1      -0.011808         -0.666161     0.009406        0.642523   \n",
       "4     1      -0.011808         -0.666161     0.009406        0.642523   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0  -0.314975             0.815565              0.959976 -0.092971 -1.359049   \n",
       "1  -0.200790            -0.931107              0.287618 -0.093888  0.506915   \n",
       "2  -0.172244            -0.029599             -0.331660 -0.093744  0.258120   \n",
       "3   0.056126             0.928254              1.243074 -0.093678 -0.177272   \n",
       "4   0.056126             0.928254              1.243074 -0.093678 -0.177272   \n",
       "\n",
       "   sulphates   alcohol  \n",
       "0  -0.546178 -1.420364  \n",
       "1  -0.277351 -0.831728  \n",
       "2  -0.613385 -0.327183  \n",
       "3  -0.882212 -0.495365  \n",
       "4  -0.882212 -0.495365  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables.'''\n",
    "\n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If type, replace all 'White'/'Red' values with 1/0\n",
    "        if col == 'type' and col_data.dtype == object:\n",
    "            col_data = col_data.replace(['White', 'Red'], [1, 0])\n",
    "        \n",
    "        # If alcohol, parse it values to numberic and coerce the convertion errors\n",
    "        if col == 'alcohol' and col_data.dtype == object:\n",
    "            col_data = pd.to_numeric(col_data, errors='coerce')\n",
    "\n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "\n",
    "    # handle NaN values by inputting the mean\n",
    "    output.fillna(output.mean(), inplace=True)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have converted all categorical features into numeric values.\n",
    "Now, we will split the data (both features and corresponding labels) into training and test sets.\n",
    "In the following code cell below, you will need to implement the following:\n",
    "\n",
    "- Randomly shuffle and split the data (X_all, y_all) into training and testing subsets.\n",
    "- Use approximately 75% for training set and approximately 25% for testing set.\n",
    "- Set a random_state for the function(s) you use, if provided.\n",
    "- Store the results in X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 4872 samples.\n",
      "Testing set has 1625 samples.\n",
      "Show if the quality classes rate is preserved across the sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>testing</th>\n",
       "      <th>training</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033246</td>\n",
       "      <td>0.032615</td>\n",
       "      <td>0.033456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.329075</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.331076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.436509</td>\n",
       "      <td>0.451692</td>\n",
       "      <td>0.431445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.166077</td>\n",
       "      <td>0.165538</td>\n",
       "      <td>0.166256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.029706</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.031609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       original   testing  training\n",
       "class                              \n",
       "3      0.004618  0.003077  0.005131\n",
       "4      0.033246  0.032615  0.033456\n",
       "5      0.329075  0.323077  0.331076\n",
       "6      0.436509  0.451692  0.431445\n",
       "7      0.166077  0.165538  0.166256\n",
       "8      0.029706  0.024000  0.031609\n",
       "9      0.000770       NaN  0.001026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the number of training points\n",
    "num_train = int(X_all.shape[0] * 0.75)\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all,\n",
    "    y_all,\n",
    "    train_size=num_train,\n",
    "    test_size=num_test,\n",
    "    random_state=42,\n",
    "    #stratify=y_all  #  EXTRA: preserve class imbalance\n",
    ")\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "print(\"Show if the quality classes rate is preserved across the sets\")\n",
    "\n",
    "cls_props = pd.DataFrame(data={\n",
    "    'original': data['quality'].value_counts() / data['quality'].shape[0],\n",
    "    'training': y_train.value_counts() / y_train.shape[0],\n",
    "    'testing': y_test.value_counts() / y_test.shape[0]\n",
    "})\n",
    "cls_props.index.name = 'class'\n",
    "display(cls_props)\n",
    "\n",
    "# sns.catplot(data=df, kind=\"count\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will choose 3 supervised learning models that are appropriate for this problem and available in scikit-learn.\n",
    "\n",
    "The code cell below initializes three helper functions which we can use for training and testing the three supervised learning models we've chosen. The functions are as follows:\n",
    "\n",
    "- `train_classifier` - takes as input a classifier and training data and fits the classifier to the data.\n",
    "- `predict_labels` - takes as input a fit classifier, features, and a target labeling and makes predictions using the F1 score.\n",
    "- `train_predict` - takes as input a classifier, and the training and testing data, and performs train_clasifier and predict_labels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print(\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Metrics\n",
    "With the predefined functions above, we will now import the three supervised learning models of our choice and run the train_predict function for each one. We will train and predict on each classifier for four different training set sizes: 25%, 50%, 75% and 100%. Hence, we should expect to have 12 different outputs below — 4 for each model using the varying training set sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DecisionTreeClassifier]\n",
      "\n",
      "data size 1218 and mean score 0.38091412734434843\n",
      "data size 2436 and mean score 0.38094599850035693\n",
      "data size 3654 and mean score 0.39902678532878544\n",
      "data size 4872 and mean score 0.40189733815908557\n",
      "\n",
      "[KNeighborsClassifier]\n",
      "\n",
      "data size 1218 and mean score 0.41781945508372925\n",
      "data size 2436 and mean score 0.3891648166685911\n",
      "data size 3654 and mean score 0.42365668580803933\n",
      "data size 4872 and mean score 0.43576714771053365\n",
      "\n",
      "[RandomForestClassifier]\n",
      "\n",
      "data size 1218 and mean score 0.5057508322550598\n",
      "data size 2436 and mean score 0.4909925580974071\n",
      "data size 3654 and mean score 0.5150585394988701\n",
      "data size 4872 and mean score 0.5186796831842511\n",
      "\n",
      "[BernoulliNB]\n",
      "\n",
      "data size 1218 and mean score 0.41447106895563507\n",
      "data size 2436 and mean score 0.4421320130021593\n",
      "data size 3654 and mean score 0.43952207734265936\n",
      "data size 4872 and mean score 0.45997885790359855\n",
      "\n",
      "[LinearDiscriminantAnalysis]\n",
      "\n",
      "data size 1218 and mean score 0.4531001202119633\n",
      "data size 2436 and mean score 0.49264929590282286\n",
      "data size 3654 and mean score 0.4865740540851719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 4872 and mean score 0.5059629845066924\n",
      "\n",
      "[LinearSVC]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 1218 and mean score 0.449925030897758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 2436 and mean score 0.49019984880392925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 3654 and mean score 0.4893247269116187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:626: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 4872 and mean score 0.5137760685279069\n",
      "\n",
      "[LogisticRegressionCV]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 1218 and mean score 0.4441372998499502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 2436 and mean score 0.500881272285995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 3654 and mean score 0.49780836679475554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 4872 and mean score 0.5188945401082906\n",
      "\n",
      "[SVC]\n",
      "\n",
      "data size 1218 and mean score 0.4769502087850048\n",
      "data size 2436 and mean score 0.5037254882469465\n",
      "data size 3654 and mean score 0.5079326957673099\n",
      "data size 4872 and mean score 0.5195097999691374\n",
      "\n",
      "[MLPClassifier]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 1218 and mean score 0.5008330918574326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 2436 and mean score 0.4999635661766943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 3654 and mean score 0.4980770925981895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/fernando/Workspace/cognitive.ai/wine-test/.env/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 4872 and mean score 0.5020512691308299\n",
      "\n",
      "[GradientBoostingClassifier]\n",
      "\n",
      "data size 1218 and mean score 0.4613990013895623\n",
      "data size 2436 and mean score 0.46474058629058423\n",
      "data size 3654 and mean score 0.4843911910107508\n",
      "data size 4872 and mean score 0.5004271779854338\n"
     ]
    }
   ],
   "source": [
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the three models\n",
    "clf_A = DecisionTreeClassifier(random_state=0)\n",
    "clf_B = KNeighborsClassifier(n_neighbors=1)\n",
    "clf_C = RandomForestClassifier(n_estimators=100)\n",
    "clf_D = BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "clf_E = LinearDiscriminantAnalysis()\n",
    "clf_F = LinearSVC(random_state=0)\n",
    "clf_G = LogisticRegressionCV(random_state=0, multi_class='multinomial')\n",
    "clf_H = SVC(gamma='auto')\n",
    "clf_I = MLPClassifier()\n",
    "clf_J = GradientBoostingClassifier()\n",
    "\n",
    "size = X_train.shape[0]\n",
    "\n",
    "# Execute the 'cross_val_score' function for each classifier and each training set size 25% 50% 75% 100%\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D, clf_E, clf_F, clf_G, clf_H, clf_I, clf_J]:\n",
    "   print(\"\\n[{}]\\n\".format(clf.__class__.__name__))\n",
    "   for n in [int(size * 0.25), int(size * 0.50), int(size * 0.75), size]:\n",
    "       cv_scores = cross_val_score(clf, X_all[:n], y_all[:n], cv=3)\n",
    "       print(\"data size {} and mean score {}\".format(n, np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
