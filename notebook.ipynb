{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this section we will perform an overview on wine dataset. It's hard to know what to do if you don't know what you're working with, so let's load our dataset and take a peek. We already know that there is only one target column: `quality`. We will discover the dataset size and number of features. We will also look the first rows to figure out all the column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0  White            7.0              0.27         0.36            20.7   \n",
       "1  White            6.3              0.30         0.34             1.6   \n",
       "2  White            8.1              0.28         0.40             6.9   \n",
       "3  White            7.2              0.23         0.32             8.5   \n",
       "4  White            7.2              0.23         0.32             8.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "\n",
       "   sulphates alcohol  quality  \n",
       "0       0.45     8.8        6  \n",
       "1       0.49     9.5        6  \n",
       "2       0.44    10.1        6  \n",
       "3       0.40     9.9        6  \n",
       "4       0.40     9.9        6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wines: 6497\n",
      "Number of features: 12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read wine dataset\n",
    "data = pd.read_csv(\"data.csv\", delimiter=\";\")\n",
    "\n",
    "# Print the first rows\n",
    "display(data.head())\n",
    "\n",
    "# Calculate number of wines in dataset\n",
    "n_wines = data.shape[0]\n",
    "\n",
    "# Calculate number of features\n",
    "n_features = data.shape[1] - 1\n",
    "\n",
    "print(\"Total number of wines: {}\".format(n_wines))\n",
    "print(\"Number of features: {}\".format(n_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset size is 6497 and it has 12 fetures. By looking the firt rows of the dataset, we have the following column types:\n",
    "\n",
    "  - `type`: Categorical (nominal)\n",
    "  - `fixed acidity`: Numeric (continuous)\n",
    "  - `volatile acidity`: Numeric (continuous)\n",
    "  - `citric acid`: Numeric (continuous)\n",
    "  - `residual sugar`: Numeric (continuous)\n",
    "  - `chlorides`: Numeric (continuous)\n",
    "  - `free sulfur dioxide`: Numeric (continuous)\n",
    "  - `total sulfur dioxide`: Numeric (continuous)\n",
    "  - `density`: Numeric (continuous)\n",
    "  - `pH`: Numeric (continuous)\n",
    "  - `sulphates`: Numeric (continuous)\n",
    "  - `alcohol`: Numeric (continuous)\n",
    "  - `quality`: Numeric (ordinal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data\n",
    "\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "## Feature columns vs target column\n",
    "\n",
    "It is often the case that the data contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "The code cell below will separate the wine data into feature and target columns to see if any features are non-numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(data.columns[:-1])\n",
    "\n",
    "# Extract target column 'quality'\n",
    "target_col = data.columns[-1]\n",
    "\n",
    "# Show the list of columns\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "print(\"\\nFeature types:\")\n",
    "print(data[feature_cols].dtypes)\n",
    "\n",
    "print(\"\\nTarget type:\")\n",
    "print(data[target_col].dtypes)\n",
    "\n",
    "print(\"\\nClasses from `type` feature:\")\n",
    "print(data['type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess features\n",
    "\n",
    "As we can see, there two non-numeric features that need to be converted: `type` and `alcohol`.\n",
    "\n",
    "The `type` feature only has two classes (`['White' 'Red']`), so it can be reasonably converted into 1/0 (binary) values.\n",
    "\n",
    "The `alcohol` feature is actually a numeric feature, but some rows are wrong non-numeric values, for example `'110.666.666.666.667'`, `'956.666.666.666.667'`, `'923.333.333.333.333'` and so on. Therefore, we will parse the values of this feature into numeric values and replace the wrong values with the mean of all of the values for the feature ([reference](https://machinelearningmastery.com/handle-missing-data-python/)).\n",
    "\n",
    "The code cell below performs the preprocessing routine discussed.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables.'''\n",
    "\n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If type, replace all 'White'/'Red' values with 1/0\n",
    "        if col == 'type' and col_data.dtype == object:\n",
    "            col_data = col_data.replace(['White', 'Red'], [1, 0])\n",
    "        \n",
    "        # If alcohol, parse it values to numberic and coerce the convertion errors\n",
    "        if col == 'alcohol' and col_data.dtype == object:\n",
    "            col_data = pd.to_numeric(col_data, errors='coerce')\n",
    "\n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "\n",
    "    # handle NaN values by inputting the mean\n",
    "    output.fillna(output.mean(), inplace=True)\n",
    "    \n",
    "    return output\n",
    "\n",
    "data = preprocess_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers and Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've successfully cleaned our data and converted it into a form which is easily consumable by machine learning algorithms. However, at this point we should consider whether or not some method of data normalization / scaling or outlier removal will be beneficial for our algorithm.\n",
    "\n",
    "Feature normalization / scaling allows for all features to contribute equally (or more aptly, it allows for features to contribute relative to their importance rather than their scale).\n",
    "\n",
    "Outliers are extreme values that deviate from other observations on data , they may indicate a variability in a measurement, experimental errors or a novelty. In other words, an outlier is an observation that diverges from an overall pattern on a sample. Some machine learning are sensitive to outliers.\n",
    "\n",
    "The code cell below plots the boxplot for all features in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(data=data[feature_cols], orient=\"h\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the features contain many (extreme) outliers. In the code cell bellow we will create a function to  perform outlier removal based on boxplot method and IQR factor (default == 1.5) ([reference](https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba)). In a later section, we will vary this factor to analyse the best threshold to remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data_orig, feature_cols, target_col, factor=1.5, verbose=False):\n",
    "    data = data_orig.copy()\n",
    "    features = feature_cols\n",
    "    Q1 = data[features].quantile(0.25)\n",
    "    Q3 = data[features].quantile(0.75)\n",
    "    IQR = Q3 - Q1    \n",
    "    is_outlier = (data[features] < (Q1 - factor * IQR)) |(data[features] > (Q3 + factor * IQR))\n",
    "    data = data[~(is_outlier).any(axis=1)]\n",
    "    if verbose:\n",
    "        print(\"Number of outliers for IQR factor {}: {}\".format(factor, data_orig.shape[0] - data.shape[0]))\n",
    "    return data[feature_cols], data[target_col]\n",
    "\n",
    "test1 = remove_outliers(data, feature_cols, target_col, verbose=True)\n",
    "test1 = remove_outliers(data, feature_cols, target_col, factor=3.5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the boxplot, the range of values varies widely between the features. We will create a function to normalize features using min-max or standard methods so that each feature contributes proportionately in the same scale in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def scale(X, scaler_type='minmax'):\n",
    "    X = X.copy() # TODO\n",
    "    scaler = MinMaxScaler()\n",
    "    if scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "    features = list(X.select_dtypes(include=['float64']).columns)\n",
    "    X[features] = scaler.fit_transform(X[features])\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data balancing\n",
    "\n",
    "A very frequent problem in machine learning models is imbalanced dataset, because an imbalanced dataset may lead to inflated performance estimates ([reference](https://stats.stackexchange.com/questions/28029/training-a-decision-tree-against-unbalanced-data)). Therefore, We will analyse if the dataset response variable is balalanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bar plot for the counts of observations in each quality class.\")\n",
    "sns.catplot(\"quality\", data=data, hue='quality', kind=\"count\")\n",
    "print(data[target_col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the response variable `quality` is very unbalanced. The code cell bellow will balance the minority classes by up-sample them. Up-sampling is the process of randomly duplicating observations from the minority class in order to reinforce its signal ([reference](https://elitedatascience.com/imbalanced-classes))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def upsample(data, target_col, majority_class):\n",
    "    '''\n",
    "    Upsample minority class based on majority_class size of a give target column\n",
    "    '''\n",
    "    target_classes = data[target_col].unique()\n",
    "    majoritary_df = data[data[target_col] == majority_class]\n",
    "    majoritary_size = majoritary_df.shape[0]\n",
    "    frames = [majoritary_df]\n",
    "\n",
    "    # combine majority class data frame with upsampled minority ones\n",
    "    for target_class in target_classes:\n",
    "        if target_class == majority_class:\n",
    "            continue\n",
    "        df = data[data[target_col] == target_class]\n",
    "        df_upsampled = resample(df, replace=True, n_samples=majoritary_size, random_state=123)\n",
    "        frames.append(df_upsampled)\n",
    "    data_balanced = pd.concat(frames)\n",
    "    return data_balanced\n",
    "\n",
    "target_majority_class = 6\n",
    "data_balanced = upsample(data, target_col, target_majority_class)\n",
    "\n",
    "print(\"Bar plot for the counts in each quality class after data balance.\")\n",
    "sns.catplot(\"quality\", data=data_balanced, hue='quality', kind=\"count\")\n",
    "print(data_balanced[target_col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "We will now import the three supervised learning models to perform the **Cross Validation** for each one using the balanced training/testing datasets.\n",
    "\n",
    "**Cross Validation** is used to assess the predictive performance score of the models and and to judge how they perform outside the sample to a new data set also known as test data. The motivation to use cross validation techniques is that when we fit a model, we are fitting it to a training dataset. Without cross validation we only have information on how does our model perform to our in-sample data. Ideally we would like to see how does the model perform when we have a new data in terms of **accuracy** of its predictions. There two types of cross validation you can perform: leave one out and **k fold** ([reference](https://www.researchgate.net/post/What_is_the_purpose_of_performing_cross-validation)). We will use the k_fold type.\n",
    "\n",
    "To find the best model, we will validate the **accuracy score** for each classifier for four different **training set sizes** (25%, 50%, 75% and 100%) and two different **normalization methods** (min-max, standard). For didactic purposes, we will also remove the outliers from the training set based on different **IQR factors** (1.5, 2.0, 2.5, 3.0) to train each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/multiclass.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def cross_validation(classifier, X, y, cv=10, size_proportions=[0.25, 0.50, 0.75, 1.0]):\n",
    "    '''\n",
    "    Execute the 'cross_val_score' function for a classifier, each \n",
    "    training set size proportion (25%, 50%, 75%, 100%), and each\n",
    "    normalization type (min-max, standard)\n",
    "    '''\n",
    "    scores = []\n",
    "    total_size = X.shape[0]\n",
    "    sizes = (map(lambda p: int(total_size * p), size_proportions))\n",
    "    X_minmax = scale(X, scaler_type='minmax')\n",
    "    X_standard = scale(X, scaler_type='standard')\n",
    "\n",
    "    for size in sizes:\n",
    "        scores1 = cross_val_score(classifier, X[:size], y[:size], cv=cv)\n",
    "        scores2 = cross_val_score(classifier, X_minmax[:size], y[:size], cv=cv)\n",
    "        scores3 = cross_val_score(classifier, X_standard[:size], y[:size], cv=cv)\n",
    "        scores.append([size, np.mean(scores1), np.mean(scores2), np.mean(scores3)])\n",
    "    result = pd.DataFrame(scores, columns=['size(X)', 'X', 'minmax(X)', 'standard(X)'])\n",
    "    return result\n",
    "\n",
    "# Initialize the models\n",
    "clf_A = DecisionTreeClassifier(random_state=0)\n",
    "clf_B = RandomForestClassifier(n_estimators=100)\n",
    "clf_C = LinearDiscriminantAnalysis()  # Variables must not be collinear\n",
    "\n",
    "classifiers = [clf_A, clf_B, clf_C]\n",
    "iqr_factors = [1.5, 2.0, 2.5, 3.0]\n",
    "size_proportions=[0.25, 0.50, 0.75, 1.0]\n",
    "cv = ShuffleSplit(n_splits=7, test_size=0.2, random_state=0)\n",
    "\n",
    "# Execute 'cross_validation' for each classifier, normalization type, training set size and iqr_factor\n",
    "for clf in classifiers:\n",
    "    print(\"\\n[{}]\\n\".format(clf.__class__.__name__))\n",
    "\n",
    "    print('Scores considering outliers')\n",
    "    X_all, y_all = data_balanced[feature_cols], data_balanced[target_col]\n",
    "    scores = cross_validation(clf, X_all, y_all, cv=cv)\n",
    "    display(scores)\n",
    "\n",
    "    for iqr_factor in iqr_factors:\n",
    "        print('Scores considering no outliers, IQR factor', iqr_factor)\n",
    "        X_all, y_all = remove_outliers(data_balanced, feature_cols, target_col, factor=iqr_factor)\n",
    "        scores = cross_validation(clf, X_all, y_all, cv=k_fold)\n",
    "        display(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO sklearn.ensemble.GradientBoostingClassifier\n",
    "# http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "# https://elitedatascience.com/imbalanced-classes\n",
    "# https://stackoverflow.com/questions/26210471/scikit-learn-gridsearch-giving-valueerror-multiclass-format-is-not-supported\n",
    "#     print(y.unique())\n",
    "#     y = label_binarize(y, classes=y.unique())\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from plot_learning_curve import plot_learning_curve\n",
    "print(plot_learning_curve)\n",
    "\n",
    "X_all, y_all = data_balanced[feature_cols], data_balanced[target_col]\n",
    "title = \"Learning Curves (Decision Tree)\"\n",
    "# Cross validation with 7 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=7, test_size=0.2, random_state=0)\n",
    "estimator = DecisionTreeClassifier(random_state=0)\n",
    "plot_learning_curve(estimator, title, X_all, y_all, ylim=(0.7, 1.01), cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "By analysing the *cross valitation time* and *accuracy score* trade-off, the model that generalizes faster and better to classify the wine quality is **DecisionTreeClassifier** trained with the full training set considering all outliers. Although the outliers removal improves the classification, a better investigation should be performed to verify whether it is a normal behavior or some error. The **accuracy score** is about **92%** and the normalization types used in the training set didn't improve the score significantly. The **learning curve** also shows that our model doesn't suffer from Overfitting and Underfitting, ie, the model has low bias and low variance between training score and cross-validation score ([reference](http://scott.fortmann-roe.com/docs/BiasVariance.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
